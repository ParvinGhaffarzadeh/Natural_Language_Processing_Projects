{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ParvinGhaffarzadeh/Natural_Language_Processing_Projects/blob/main/TextMining_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee60b59e",
      "metadata": {
        "id": "ee60b59e"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc21fc1d",
      "metadata": {
        "id": "fc21fc1d",
        "outputId": "df74e0e9-2be4-46fc-b765-f8d061572a59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "975c4191",
      "metadata": {
        "id": "975c4191"
      },
      "outputs": [],
      "source": [
        " sample_txt='''The main purpose of using clustering techniques is to divide a dataset into a few unsupervised data analysis partitions. One of the recent and apparently one of the easiest one of them is k-means. This technique is based on square error criterion. To\n",
        "solve the combinatorial optimization issues in the context of clustering techniques, k-means algorithm was used recently.\n",
        "In spite of the fact that it has been applied to a few territories, it experiences sensitivity to initial points. There have been a\n",
        "few techniques that were reported beneficial for improving kmeans systems. By this paper we are trying to suggest a new algorithm which depends on an optimized clustering method. This algorithm that is called K-Means Modified Grenade\n",
        "Explosion Method (KMGEM) is a K-Means that initialized with Modified Grenade Explosion algorithm. The results showed that our proposed method is superior in comparison with methods like Genetic Algorithm, Genetic K-Means\n",
        "Algorithm, and k-means algorithms.'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e86489e",
      "metadata": {
        "id": "6e86489e"
      },
      "source": [
        "# Text to sentences tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b725e1e6",
      "metadata": {
        "id": "b725e1e6"
      },
      "outputs": [],
      "source": [
        "sentences= nltk.sent_tokenize(sample_txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ce597ea",
      "metadata": {
        "id": "9ce597ea",
        "outputId": "3e25bb11-1b6a-40bf-aa4c-3ee564db50d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The main purpose of using clustering techniques is to divide a dataset into a few unsupervised data analysis partitions.',\n",
              " 'One of the recent and apparently one of the easiest one of them is k-means.',\n",
              " 'This technique is based on square error criterion.',\n",
              " 'To\\nsolve the combinatorial optimization issues in the context of clustering techniques, k-means algorithm was used recently.',\n",
              " 'In spite of the fact that it has been applied to a few territories, it experiences sensitivity to initial points.',\n",
              " 'There have been a\\nfew techniques that were reported beneficial for improving kmeans systems.',\n",
              " 'By this paper we are trying to suggest a new algorithm which depends on an optimized clustering method.',\n",
              " 'This algorithm that is called K-Means Modified Grenade\\nExplosion Method (KMGEM) is a K-Means that initialized with Modified Grenade Explosion algorithm.',\n",
              " 'The results showed that our proposed method is superior in comparison with methods like Genetic Algorithm, Genetic K-Means\\nAlgorithm, and k-means algorithms.']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2403f15",
      "metadata": {
        "id": "c2403f15"
      },
      "source": [
        "# text to Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11034d62",
      "metadata": {
        "id": "11034d62"
      },
      "outputs": [],
      "source": [
        "words= nltk.word_tokenize(sample_txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "142b3bae",
      "metadata": {
        "id": "142b3bae",
        "outputId": "c729ce7f-1c50-4dee-80d1-912e645c4daf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The',\n",
              " 'main',\n",
              " 'purpose',\n",
              " 'of',\n",
              " 'using',\n",
              " 'clustering',\n",
              " 'techniques',\n",
              " 'is',\n",
              " 'to',\n",
              " 'divide',\n",
              " 'a',\n",
              " 'dataset',\n",
              " 'into',\n",
              " 'a',\n",
              " 'few',\n",
              " 'unsupervised',\n",
              " 'data',\n",
              " 'analysis',\n",
              " 'partitions',\n",
              " '.',\n",
              " 'One',\n",
              " 'of',\n",
              " 'the',\n",
              " 'recent',\n",
              " 'and',\n",
              " 'apparently',\n",
              " 'one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'easiest',\n",
              " 'one',\n",
              " 'of',\n",
              " 'them',\n",
              " 'is',\n",
              " 'k-means',\n",
              " '.',\n",
              " 'This',\n",
              " 'technique',\n",
              " 'is',\n",
              " 'based',\n",
              " 'on',\n",
              " 'square',\n",
              " 'error',\n",
              " 'criterion',\n",
              " '.',\n",
              " 'To',\n",
              " 'solve',\n",
              " 'the',\n",
              " 'combinatorial',\n",
              " 'optimization',\n",
              " 'issues',\n",
              " 'in',\n",
              " 'the',\n",
              " 'context',\n",
              " 'of',\n",
              " 'clustering',\n",
              " 'techniques',\n",
              " ',',\n",
              " 'k-means',\n",
              " 'algorithm',\n",
              " 'was',\n",
              " 'used',\n",
              " 'recently',\n",
              " '.',\n",
              " 'In',\n",
              " 'spite',\n",
              " 'of',\n",
              " 'the',\n",
              " 'fact',\n",
              " 'that',\n",
              " 'it',\n",
              " 'has',\n",
              " 'been',\n",
              " 'applied',\n",
              " 'to',\n",
              " 'a',\n",
              " 'few',\n",
              " 'territories',\n",
              " ',',\n",
              " 'it',\n",
              " 'experiences',\n",
              " 'sensitivity',\n",
              " 'to',\n",
              " 'initial',\n",
              " 'points',\n",
              " '.',\n",
              " 'There',\n",
              " 'have',\n",
              " 'been',\n",
              " 'a',\n",
              " 'few',\n",
              " 'techniques',\n",
              " 'that',\n",
              " 'were',\n",
              " 'reported',\n",
              " 'beneficial',\n",
              " 'for',\n",
              " 'improving',\n",
              " 'kmeans',\n",
              " 'systems',\n",
              " '.',\n",
              " 'By',\n",
              " 'this',\n",
              " 'paper',\n",
              " 'we',\n",
              " 'are',\n",
              " 'trying',\n",
              " 'to',\n",
              " 'suggest',\n",
              " 'a',\n",
              " 'new',\n",
              " 'algorithm',\n",
              " 'which',\n",
              " 'depends',\n",
              " 'on',\n",
              " 'an',\n",
              " 'optimized',\n",
              " 'clustering',\n",
              " 'method',\n",
              " '.',\n",
              " 'This',\n",
              " 'algorithm',\n",
              " 'that',\n",
              " 'is',\n",
              " 'called',\n",
              " 'K-Means',\n",
              " 'Modified',\n",
              " 'Grenade',\n",
              " 'Explosion',\n",
              " 'Method',\n",
              " '(',\n",
              " 'KMGEM',\n",
              " ')',\n",
              " 'is',\n",
              " 'a',\n",
              " 'K-Means',\n",
              " 'that',\n",
              " 'initialized',\n",
              " 'with',\n",
              " 'Modified',\n",
              " 'Grenade',\n",
              " 'Explosion',\n",
              " 'algorithm',\n",
              " '.',\n",
              " 'The',\n",
              " 'results',\n",
              " 'showed',\n",
              " 'that',\n",
              " 'our',\n",
              " 'proposed',\n",
              " 'method',\n",
              " 'is',\n",
              " 'superior',\n",
              " 'in',\n",
              " 'comparison',\n",
              " 'with',\n",
              " 'methods',\n",
              " 'like',\n",
              " 'Genetic',\n",
              " 'Algorithm',\n",
              " ',',\n",
              " 'Genetic',\n",
              " 'K-Means',\n",
              " 'Algorithm',\n",
              " ',',\n",
              " 'and',\n",
              " 'k-means',\n",
              " 'algorithms',\n",
              " '.']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdae255c",
      "metadata": {
        "id": "cdae255c"
      },
      "outputs": [],
      "source": [
        "from hazm import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c477f1a",
      "metadata": {
        "id": "0c477f1a"
      },
      "outputs": [],
      "source": [
        "sample_persian='''عمدتاً صاف. امکان وجود گردوخاک و غبار در مناطق زرد وجود دارد. بیشینه 37سیلسیوس. وزش باد شمال غرب از 25 تا 40 کیلومتر فی ساعت.'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "024d6539",
      "metadata": {
        "id": "024d6539"
      },
      "outputs": [],
      "source": [
        "sentences_per=sent_tokenize(sample_persian)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7aea9a2",
      "metadata": {
        "id": "d7aea9a2",
        "outputId": "8044f74d-9ab5-4223-c8e0-5a7ea66a49cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The main purpose of using clustering techniques is to divide a dataset into a few unsupervised data analysis partitions.',\n",
              " 'One of the recent and apparently one of the easiest one of them is k-means.',\n",
              " 'This technique is based on square error criterion.',\n",
              " 'To\\nsolve the combinatorial optimization issues in the context of clustering techniques, k-means algorithm was used recently.',\n",
              " 'In spite of the fact that it has been applied to a few territories, it experiences sensitivity to initial points.',\n",
              " 'There have been a\\nfew techniques that were reported beneficial for improving kmeans systems.',\n",
              " 'By this paper we are trying to suggest a new algorithm which depends on an optimized clustering method.',\n",
              " 'This algorithm that is called K-Means Modified Grenade\\nExplosion Method (KMGEM) is a K-Means that initialized with Modified Grenade Explosion algorithm.',\n",
              " 'The results showed that our proposed method is superior in comparison with methods like Genetic Algorithm, Genetic K-Means\\nAlgorithm, and k-means algorithms.']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a36e789",
      "metadata": {
        "id": "4a36e789"
      },
      "outputs": [],
      "source": [
        "words2=word_tokenize(sample_persian)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "850f0bb5",
      "metadata": {
        "id": "850f0bb5",
        "outputId": "0f3895b0-8746-468a-b837-a6d57b35d9d8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['عمدتاً',\n",
              " 'صاف',\n",
              " '.',\n",
              " 'امکان',\n",
              " 'وجود',\n",
              " 'گردوخاک',\n",
              " 'و',\n",
              " 'غبار',\n",
              " 'در',\n",
              " 'مناطق',\n",
              " 'زرد',\n",
              " 'وجود',\n",
              " 'دارد',\n",
              " '.',\n",
              " 'بیشینه',\n",
              " '37',\n",
              " 'سیلسیوس',\n",
              " '.',\n",
              " 'وزش',\n",
              " 'باد',\n",
              " 'شمال',\n",
              " 'غرب',\n",
              " 'از',\n",
              " '25',\n",
              " 'تا',\n",
              " '40',\n",
              " 'کیلومتر',\n",
              " 'فی',\n",
              " 'ساعت',\n",
              " '.']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aee8ce12",
      "metadata": {
        "id": "aee8ce12"
      },
      "source": [
        "# حذف تشدید و فاصله تبدیل به نیم فاصله با نرمال کردن دیتا"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08d8aa16",
      "metadata": {
        "id": "08d8aa16"
      },
      "outputs": [],
      "source": [
        "test= '''من با دقّت مطالعه می کنم'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1852c68",
      "metadata": {
        "id": "a1852c68"
      },
      "outputs": [],
      "source": [
        "normalize=Normalizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9b56770",
      "metadata": {
        "id": "c9b56770"
      },
      "outputs": [],
      "source": [
        "normal_txt=normalize.normalize(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a31484b0",
      "metadata": {
        "id": "a31484b0",
        "outputId": "78be5789-ece7-4e37-f074-1d9eedd3d2c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'من با دقت مطالعه می\\u200cکنم'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "normal_txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "117e663a",
      "metadata": {
        "id": "117e663a"
      },
      "source": [
        "# stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88f240ef",
      "metadata": {
        "id": "88f240ef"
      },
      "outputs": [],
      "source": [
        "from nltk.stem.porter import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7207cfd",
      "metadata": {
        "id": "e7207cfd"
      },
      "outputs": [],
      "source": [
        "tokens=[\"connection\",\"connecting\",\"disconnect\",\"conncet\",\"connected\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84332ed1",
      "metadata": {
        "id": "84332ed1"
      },
      "outputs": [],
      "source": [
        "stemmer= PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96b6f470",
      "metadata": {
        "id": "96b6f470",
        "outputId": "fc65136e-3b8b-4889-fe77-8e1cfe48c522"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "connection ---> connect\n",
            "connecting ---> connect\n",
            "disconnect ---> disconnect\n",
            "conncet ---> conncet\n",
            "connected ---> connect\n"
          ]
        }
      ],
      "source": [
        "for token in tokens:\n",
        "    print(token,'--->',stemmer.stem(token))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c65c8b3",
      "metadata": {
        "id": "3c65c8b3"
      },
      "source": [
        "rule table in stemmer\n",
        "another stemmer is lancaster ---> overstemming due to algorithm is iterative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fc4fc4b",
      "metadata": {
        "id": "2fc4fc4b"
      },
      "outputs": [],
      "source": [
        "from nltk.stem.lancaster import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf400433",
      "metadata": {
        "id": "bf400433"
      },
      "outputs": [],
      "source": [
        "lancaster=LancasterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e02d3e1",
      "metadata": {
        "id": "0e02d3e1"
      },
      "outputs": [],
      "source": [
        "tokens=[\"lovely\",\"decentralized\",\"better\",\"information\",\"disable\",\"did\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49fa3140",
      "metadata": {
        "id": "49fa3140",
        "outputId": "ab7acc1d-a6e4-41a7-db96-a715b311b80e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lovely -> love\n",
            "lovely -> lov\n",
            "==========\n",
            "decentralized -> decentr\n",
            "decentralized -> dec\n",
            "==========\n",
            "better -> better\n",
            "better -> bet\n",
            "==========\n",
            "information -> inform\n",
            "information -> inform\n",
            "==========\n",
            "disable -> disabl\n",
            "disable -> dis\n",
            "==========\n",
            "did -> did\n",
            "did -> did\n",
            "==========\n"
          ]
        }
      ],
      "source": [
        "for token in tokens:\n",
        "    print(token,'->',stemmer.stem(token))\n",
        "    print(token,'->',lancaster.stem(token))\n",
        "    print('==========')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9a9f88b",
      "metadata": {
        "id": "b9a9f88b"
      },
      "source": [
        "lemo is dictionary root which each of roots are meaningful"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87a4cc4a",
      "metadata": {
        "id": "87a4cc4a"
      },
      "outputs": [],
      "source": [
        "from nltk.stem.wordnet import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "846cb306",
      "metadata": {
        "id": "846cb306"
      },
      "outputs": [],
      "source": [
        "lemmatizer= WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0a70c1a",
      "metadata": {
        "id": "d0a70c1a",
        "outputId": "575c4bd0-e4d0-43f1-8cb4-3281e4c6546b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lovely -> love\n",
            "lovely -> lovely\n",
            "==========\n",
            "decentralized -> decentr\n",
            "decentralized -> decentralized\n",
            "==========\n",
            "better -> better\n",
            "better -> better\n",
            "==========\n",
            "information -> inform\n",
            "information -> information\n",
            "==========\n",
            "disable -> disabl\n",
            "disable -> disable\n",
            "==========\n",
            "did -> did\n",
            "did -> did\n",
            "==========\n"
          ]
        }
      ],
      "source": [
        "for token in tokens:\n",
        "    print(token,'->',stemmer.stem(token))\n",
        "    print(token,'->',lemmatizer.lemmatize(token))\n",
        "    print('==========')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66eb8103",
      "metadata": {
        "id": "66eb8103",
        "outputId": "b6f7d756-1c85-46b6-bd7e-903d0a01ac98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lovely -> love\n",
            "lovely -> lovely\n",
            "==========\n",
            "decentralized -> decentr\n",
            "decentralized -> decentralized\n",
            "==========\n",
            "better -> better\n",
            "better -> good\n",
            "==========\n",
            "information -> inform\n",
            "information -> information\n",
            "==========\n",
            "disable -> disabl\n",
            "disable -> disable\n",
            "==========\n",
            "did -> did\n",
            "did -> did\n",
            "==========\n"
          ]
        }
      ],
      "source": [
        "for token in tokens:\n",
        "    print(token,'->',stemmer.stem(token))\n",
        "    print(token,'->',lemmatizer.lemmatize(token,pos='a'))\n",
        "    print('==========')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39504ea7",
      "metadata": {
        "id": "39504ea7",
        "outputId": "0384271d-35d6-4d1b-b7ee-03bd58ea1d42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lovely -> love\n",
            "lovely -> lovely\n",
            "==========\n",
            "decentralized -> decentr\n",
            "decentralized -> decentralize\n",
            "==========\n",
            "better -> better\n",
            "better -> better\n",
            "==========\n",
            "information -> inform\n",
            "information -> information\n",
            "==========\n",
            "disable -> disabl\n",
            "disable -> disable\n",
            "==========\n",
            "did -> did\n",
            "did -> do\n",
            "==========\n"
          ]
        }
      ],
      "source": [
        "for token in tokens:\n",
        "    print(token,'->',stemmer.stem(token))\n",
        "    print(token,'->',lemmatizer.lemmatize(token,pos='v'))\n",
        "    print('==========')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2666164e",
      "metadata": {
        "id": "2666164e"
      },
      "outputs": [],
      "source": [
        "from hazm import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b069c925",
      "metadata": {
        "id": "b069c925"
      },
      "outputs": [],
      "source": [
        "per_token=[\"کتاب ها\",\"کتابم\",\"کتابی\",\"رفت\",\"کتابخوانی\",\"رفتی\",\"می روم\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a117d026",
      "metadata": {
        "id": "a117d026"
      },
      "outputs": [],
      "source": [
        "stemmer = Stemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e891a1a",
      "metadata": {
        "id": "7e891a1a"
      },
      "outputs": [],
      "source": [
        "lemmatizer = Lemmatizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25f68e48",
      "metadata": {
        "id": "25f68e48"
      },
      "source": [
        "first Normalize data bc of ha with space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67208b7e",
      "metadata": {
        "id": "67208b7e"
      },
      "outputs": [],
      "source": [
        "normalizer= Normalizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e770401a",
      "metadata": {
        "id": "e770401a",
        "outputId": "e5bb0499-7980-4bf0-b348-d1cf01ee77ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "کتاب‌ها -> کتاب\n",
            "کتاب‌ها -> کتاب\n",
            "==========\n",
            "کتابم -> کتاب\n",
            "کتابم -> کتاب\n",
            "==========\n",
            "کتابی -> کتاب\n",
            "کتابی -> کتاب\n",
            "==========\n",
            "رفت -> رف\n",
            "رفت -> رف\n",
            "==========\n",
            "کتابخوانی -> کتابخوان\n",
            "کتابخوانی -> کتابخوانی\n",
            "==========\n",
            "رفتی -> رفت\n",
            "رفتی -> رفتی\n",
            "==========\n",
            "می‌روم -> می‌رو\n",
            "می‌روم -> می‌روم\n",
            "==========\n"
          ]
        }
      ],
      "source": [
        "for token in per_token:\n",
        "    token=normalizer.normalize(token)\n",
        "    print(token,'->',stemmer.stem(token))\n",
        "    print(token,'->',lemmatizer.lemmatize(token,pos='v'))\n",
        "    print('==========')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59f4b7e0",
      "metadata": {
        "id": "59f4b7e0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "textmining_test.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}